{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VyacheslavGusev/Neural_networks/blob/main/Intro_to_NN_4_(HW).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "l4VAzKlG8aHj"
      },
      "source": [
        "## Neural Part Of Speech Tagging\n",
        "\n",
        "We're now going to solve the same problem of POS tagging with neural networks.\n",
        "<img src=https://i.stack.imgur.com/6pdIT.png width=320>\n",
        "\n",
        "From deep learning perspective, this is a task of predicting a sequence of outputs aligned to a sequence of inputs. There are several problems that match this formulation:\n",
        "* Part Of Speech Tagging -  an auxuliary task for many NLP problems\n",
        "* Named Entity Recognition - for chat bots and web crawlers\n",
        "* Protein structure prediction - for bioinformatics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wnu9D3YZoH2e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd3ed87f-0295-43d1-8642-69e673f43a8e"
      },
      "source": [
        "%tensorflow_version 2.x"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab only includes TensorFlow 2.x; %tensorflow_version has no effect.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "yxFUBtb88aHq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "102c858e-5dff-411a-e016-71b56e932160"
      },
      "source": [
        "import nltk\n",
        "import sys\n",
        "import numpy as np\n",
        "\n",
        "nltk.download('brown')\n",
        "nltk.download('universal_tagset')\n",
        "data = nltk.corpus.brown.tagged_sents(tagset='universal')\n",
        "all_tags = ['#EOS#','#UNK#','ADV', 'NOUN', 'ADP', 'PRON', 'DET', '.', 'PRT', 'VERB', 'X', 'NUM', 'CONJ', 'ADJ']\n",
        "\n",
        "data = np.array([ [(word.lower(),tag) for word,tag in sentence] for sentence in data ])"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/brown.zip.\n",
            "[nltk_data] Downloading package universal_tagset to /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/universal_tagset.zip.\n",
            "<ipython-input-1-bc9847c14597>:10: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  data = np.array([ [(word.lower(),tag) for word,tag in sentence] for sentence in data ])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bq_OXuD38aHs"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_data, test_data = train_test_split(data,test_size=0.25,random_state=42)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sAlXrDmU8aHs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 152
        },
        "outputId": "088097a3-5654-4134-f763-f8674b1c54d2"
      },
      "source": [
        "from IPython.display import HTML, display\n",
        "def draw(sentence):\n",
        "    words,tags = zip(*sentence)\n",
        "    display(HTML('<table><tr>{tags}</tr>{words}<tr></table>'.format(\n",
        "                words = '<td>{}</td>'.format('</td><td>'.join(words)),\n",
        "                tags = '<td>{}</td>'.format('</td><td>'.join(tags)))))\n",
        "\n",
        "\n",
        "draw(data[11])\n",
        "draw(data[10])\n",
        "draw(data[7])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table><tr><td>NOUN</td><td>ADP</td><td>NOUN</td><td>NOUN</td><td>NOUN</td><td>NOUN</td><td>VERB</td><td>ADV</td><td>VERB</td><td>ADP</td><td>DET</td><td>ADJ</td><td>NOUN</td><td>.</td></tr><td>implementation</td><td>of</td><td>georgia's</td><td>automobile</td><td>title</td><td>law</td><td>was</td><td>also</td><td>recommended</td><td>by</td><td>the</td><td>outgoing</td><td>jury</td><td>.</td><tr></table>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table><tr><td>PRON</td><td>VERB</td><td>ADP</td><td>DET</td><td>NOUN</td><td>.</td><td>VERB</td><td>NOUN</td><td>PRT</td><td>VERB</td><td>.</td><td>DET</td><td>NOUN</td><td>.</td></tr><td>it</td><td>urged</td><td>that</td><td>the</td><td>city</td><td>``</td><td>take</td><td>steps</td><td>to</td><td>remedy</td><td>''</td><td>this</td><td>problem</td><td>.</td><tr></table>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table><tr><td>NOUN</td><td>VERB</td></tr><td>merger</td><td>proposed</td><tr></table>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LAViiL2C8aHt"
      },
      "source": [
        "### Building vocabularies\n",
        "\n",
        "Just like before, we have to build a mapping from tokens to integer ids. This time around, our model operates on a word level, processing one word per RNN step. This means we'll have to deal with far larger vocabulary.\n",
        "\n",
        "Luckily for us, we only receive those words as input i.e. we don't have to predict them. This means we can have a large vocabulary for free by using word embeddings."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Создание словарей\n",
        "Как и раньше, мы должны построить отображение от токенов к целочисленным идентификаторам. На этот раз наша модель работает на уровне слов, обрабатывая одно слово за шаг RNN. Это означает, что нам придется иметь дело с гораздо большим словарным запасом.\n",
        "\n",
        "К счастью для нас, мы получаем только эти слова в качестве входных данных, т.е. нам не нужно их предсказывать. Это означает, что мы можем бесплатно получить большой словарный запас, используя встраивания слов."
      ],
      "metadata": {
        "id": "57l0g4nIUDdM"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "ZXK_k-mo8aHt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0711d641-91e8-497b-ac87-c71099207474"
      },
      "source": [
        "from collections import Counter\n",
        "word_counts = Counter()\n",
        "for sentence in data:\n",
        "    words,tags = zip(*sentence)\n",
        "    word_counts.update(words)\n",
        "\n",
        "all_words = ['#EOS#','#UNK#'] + list(list(zip(*word_counts.most_common(10000)))[0])\n",
        "\n",
        "#let's measure what fraction of data words are in the dictionary\n",
        "print(\"Coverage = %.5f\" % (float(sum(word_counts[w] for w in all_words)) / sum(word_counts.values())))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Coverage = 0.92876\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "T0hee8L88aHt"
      },
      "source": [
        "from collections import defaultdict\n",
        "word_to_id = defaultdict(lambda:1, { word: i for i, word in enumerate(all_words) })\n",
        "tag_to_id = { tag: i for i, tag in enumerate(all_tags)}"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RCmGbwpP8aHu"
      },
      "source": [
        "convert words and tags into fixed-size matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "X7kx6jWn8aHu"
      },
      "source": [
        "def to_matrix(lines, token_to_id, max_len=None, pad=0, dtype='int32', time_major=False):\n",
        "    \"\"\"Converts a list of names into rnn-digestable matrix with paddings added after the end\"\"\"\n",
        "\n",
        "    max_len = max_len or max(map(len,lines))\n",
        "    matrix = np.empty([len(lines), max_len],dtype)\n",
        "    matrix.fill(pad)\n",
        "\n",
        "    for i in range(len(lines)):\n",
        "        line_ix = list(map(token_to_id.__getitem__,lines[i]))[:max_len]\n",
        "        matrix[i,:len(line_ix)] = line_ix\n",
        "\n",
        "    return matrix.T if time_major else matrix"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BCaE-i5u8aHu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "509fd45b-2b23-4c2a-e22f-21436ed2df34"
      },
      "source": [
        "batch_words, batch_tags = zip(*[zip(*sentence) for sentence in data[-3:]])\n",
        "\n",
        "print(\"Word ids:\")\n",
        "print(to_matrix(batch_words, word_to_id))\n",
        "print(\"Tag ids:\")\n",
        "print(to_matrix(batch_tags, tag_to_id))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word ids:\n",
            "[[   2 3057    5    2 2238 1334 4238 2454    3    6   19   26 1070   69\n",
            "     8 2088    6    3    1    3  266   65  342    2    1    3    2  315\n",
            "     1    9   87  216 3322   69 1558    4    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0]\n",
            " [  45   12    8  511 8419    6   60 3246   39    2    1    1    3    2\n",
            "   845    1    3    1    3   10 9910    2    1 3470    9   43    1    1\n",
            "     3    6    2 1046  385   73 4562    3    9    2    1    1 3250    3\n",
            "    12   10    2  861 5240   12    8 8936  121    1    4]\n",
            " [  33   64   26   12  445    7 7346    9    8 3337    3    1 2811    3\n",
            "     2  463  572    2    1    1 1649   12    1    4    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0]]\n",
            "Tag ids:\n",
            "[[ 6  3  4  6  3  3  9  9  7 12  4  5  9  4  6  3 12  7  9  7  9  8  4  6\n",
            "   3  7  6 13  3  4  6  3  9  4  3  7  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0]\n",
            " [ 5  9  6  9  3 12  6  3  7  6 13  3  7  6 13  3  7 13  7  5  9  6  3  3\n",
            "   4  6 13  3  7 12  6  3  6 13  3  7  4  6  3  9  3  7  9  4  6 13  3  9\n",
            "   6  3  2 13  7]\n",
            " [ 4  6  5  9 13  4  3  4  6 13  7 13  3  7  6  3  4  6 13  3  3  9  9  7\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "_oK_i5Xa8aHv"
      },
      "source": [
        "### Build model\n",
        "\n",
        "Unlike our previous lab, this time we'll focus on a high-level keras interface to recurrent neural networks. It is as simple as you can get with RNN, allbeit somewhat constraining for complex tasks like seq2seq.\n",
        "\n",
        "By default, all keras RNNs apply to a whole sequence of inputs and produce a sequence of hidden states `(return_sequences=True` or just the last hidden state `(return_sequences=False)`. All the recurrence is happening under the hood.\n",
        "\n",
        "At the top of our model we need to apply a Dense layer to each time-step independently. As of now, by default keras.layers.Dense would apply once to all time-steps concatenated. We use __keras.layers.TimeDistributed__ to modify Dense layer so that it would apply across both batch and time axes."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Создание модели\n",
        "В отличие от нашей предыдущей лабораторной работы, на этот раз мы сосредоточимся на высокоуровневом интерфейсе keras для рекуррентных нейронных сетей. Он настолько прост, насколько это возможно с помощью RUN, хотя и несколько ограничен для сложных задач, таких как seq2 seq.\n",
        "\n",
        "По умолчанию все RNN keras применяются ко всей последовательности входных данных и выдают последовательность скрытых состояний (return_sequences=True или только последнее скрытое состояние (return_sequences=False). Все повторения происходят под капотом.\n",
        "\n",
        "В верхней части нашей модели нам нужно нанести плотный слой на каждый временной шаг независимо. На данный момент по умолчанию используется keras.слои.Dense будет применяться один раз ко всем объединенным временным шагам. Мы используем keras.слои.TimeDistributed для изменения плотного слоя таким образом, чтобы он применялся как по пакетной, так и по временной осям."
      ],
      "metadata": {
        "id": "fH4YR4fQcRwD"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQeb8d5j8aHv"
      },
      "source": [
        "import keras\n",
        "import keras.layers as L\n",
        "\n",
        "model = keras.models.Sequential()\n",
        "model.add(L.InputLayer([None],dtype='int32'))\n",
        "model.add(L.Embedding(len(all_words),50))\n",
        "model.add(L.SimpleRNN(64,return_sequences=True))\n",
        "\n",
        "#add top layer that predicts tag probabilities\n",
        "stepwise_dense = L.Dense(len(all_tags),activation='softmax')\n",
        "stepwise_dense = L.TimeDistributed(stepwise_dense)\n",
        "model.add(stepwise_dense)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lQbJqM2n8aHv"
      },
      "source": [
        "__Training:__ in this case we don't want to prepare the whole training dataset in advance. The main cause is that the length of every batch depends on the maximum sentence length within the batch. This leaves us two options: use custom training code as in previous seminar or use generators.\n",
        "\n",
        "Keras models have a __`model.fit_generator`__ method that accepts a python generator yielding one batch at a time. But first we need to implement such generator:"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Обучение: в этом случае мы не хотим заранее подготавливать весь набор обучающих данных. Основная причина в том, что длина каждого пакета зависит от максимальной длины предложения в пакете. Это оставляет нам два варианта: использовать пользовательский обучающий код, как на предыдущем семинаре, или использовать генераторы.\n",
        "\n",
        "В моделях Keras есть метод model.fit_generator, который принимает генератор python, выдающий по одному пакету за раз. Но сначала нам нужно реализовать такой генератор:"
      ],
      "metadata": {
        "id": "-02BVg7Tc-10"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "kpeMsDi18aHw"
      },
      "source": [
        "import tensorflow\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "BATCH_SIZE=32\n",
        "def generate_batches(sentences,batch_size=BATCH_SIZE,max_len=None,pad=0):\n",
        "    assert isinstance(sentences,np.ndarray),\"Make sure sentences is q numpy array\"\n",
        "\n",
        "    while True:\n",
        "        indices = np.random.permutation(np.arange(len(sentences)))\n",
        "        for start in range(0,len(indices)-1,batch_size):\n",
        "            batch_indices = indices[start:start+batch_size]\n",
        "            batch_words,batch_tags = [],[]\n",
        "            for sent in sentences[batch_indices]:\n",
        "                words,tags = zip(*sent)\n",
        "                batch_words.append(words)\n",
        "                batch_tags.append(tags)\n",
        "\n",
        "            batch_words = to_matrix(batch_words,word_to_id,max_len,pad)\n",
        "            batch_tags = to_matrix(batch_tags,tag_to_id,max_len,pad)\n",
        "\n",
        "            batch_tags_1hot = to_categorical(batch_tags,len(all_tags)).reshape(batch_tags.shape+(-1,))\n",
        "            yield batch_words,batch_tags_1hot\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zYoR9vgn8aHw"
      },
      "source": [
        "__Callbacks:__ Another thing we need is to measure model performance. The tricky part is not to count accuracy after sentence ends (on padding) and making sure we count all the validation data exactly once.\n",
        "\n",
        "While it isn't impossible to persuade Keras to do all of that, we may as well write our own callback that does that.\n",
        "Keras callbacks allow you to write a custom code to be ran once every epoch or every minibatch. We'll define one via LambdaCallback"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "CC8woNtV8aHx"
      },
      "source": [
        "def compute_test_accuracy(model):\n",
        "    test_words,test_tags = zip(*[zip(*sentence) for sentence in test_data])\n",
        "    test_words,test_tags = to_matrix(test_words,word_to_id),to_matrix(test_tags,tag_to_id)\n",
        "\n",
        "    #predict tag probabilities of shape [batch,time,n_tags]\n",
        "    predicted_tag_probabilities = model.predict(test_words,verbose=1)\n",
        "    predicted_tags = predicted_tag_probabilities.argmax(axis=-1)\n",
        "\n",
        "    #compute accurary excluding padding\n",
        "    numerator = np.sum(np.logical_and((predicted_tags == test_tags),(test_words != 0)))\n",
        "    denominator = np.sum(test_words != 0)\n",
        "    return float(numerator)/denominator\n",
        "\n",
        "\n",
        "class EvaluateAccuracy(keras.callbacks.Callback):\n",
        "    def on_epoch_end(self,epoch,logs=None):\n",
        "        sys.stdout.flush()\n",
        "        print(\"\\nMeasuring validation accuracy...\")\n",
        "        acc = compute_test_accuracy(self.model)\n",
        "        print(\"\\nValidation accuracy: %.5f\\n\"%acc)\n",
        "        sys.stdout.flush()"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "5eJGEWu58aHx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0367d5c-9d12-4869-9417-81f14d2854f3"
      },
      "source": [
        "model.compile('adam','categorical_crossentropy')\n",
        "\n",
        "model.fit_generator(generate_batches(train_data),len(train_data)/BATCH_SIZE,\n",
        "                    callbacks=[EvaluateAccuracy()], epochs=5,)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-e75a6e7fae6a>:3: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  model.fit_generator(generate_batches(train_data),len(train_data)/BATCH_SIZE,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1344/1343 [==============================] - ETA: 0s - loss: 0.2619\n",
            "Measuring validation accuracy...\n",
            "448/448 [==============================] - 8s 17ms/step\n",
            "\n",
            "Validation accuracy: 0.93980\n",
            "\n",
            "1343/1343 [==============================] - 139s 97ms/step - loss: 0.2619\n",
            "Epoch 2/5\n",
            "1344/1343 [==============================] - ETA: 0s - loss: 0.0593\n",
            "Measuring validation accuracy...\n",
            "448/448 [==============================] - 7s 17ms/step\n",
            "\n",
            "Validation accuracy: 0.94442\n",
            "\n",
            "1343/1343 [==============================] - 101s 75ms/step - loss: 0.0593\n",
            "Epoch 3/5\n",
            "1343/1343 [============================>.] - ETA: 0s - loss: 0.0516\n",
            "Measuring validation accuracy...\n",
            "448/448 [==============================] - 8s 17ms/step\n",
            "\n",
            "Validation accuracy: 0.94558\n",
            "\n",
            "1343/1343 [==============================] - 99s 74ms/step - loss: 0.0516\n",
            "Epoch 4/5\n",
            "1344/1343 [==============================] - ETA: 0s - loss: 0.0471\n",
            "Measuring validation accuracy...\n",
            "448/448 [==============================] - 8s 19ms/step\n",
            "\n",
            "Validation accuracy: 0.94625\n",
            "\n",
            "1343/1343 [==============================] - 100s 74ms/step - loss: 0.0471\n",
            "Epoch 5/5\n",
            "1344/1343 [==============================] - ETA: 0s - loss: 0.0433\n",
            "Measuring validation accuracy...\n",
            "448/448 [==============================] - 8s 17ms/step\n",
            "\n",
            "Validation accuracy: 0.94540\n",
            "\n",
            "1343/1343 [==============================] - 97s 72ms/step - loss: 0.0433\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7e398ff54d30>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TTN7C34V8aHy"
      },
      "source": [
        "Measure final accuracy on the whole test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "tHgxnYB68aHy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d774886-b7fd-4446-c812-8ac69db5cd22"
      },
      "source": [
        "acc = compute_test_accuracy(model)\n",
        "print(\"Final accuracy: %.5f\"%acc)\n",
        "\n",
        "assert acc>0.94, \"Keras has gone on a rampage again, please contact course staff.\""
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "448/448 [==============================] - 7s 16ms/step\n",
            "Final accuracy: 0.94540\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5L5Prr4I8aHy"
      },
      "source": [
        "### Going bidirectional\n",
        "\n",
        "Since we're analyzing a full sequence, it's legal for us to look into future data.\n",
        "\n",
        "A simple way to achieve that is to go both directions at once, making a __bidirectional RNN__.\n",
        "\n",
        "In Keras you can achieve that both manually (using two LSTMs and Concatenate) and by using __`keras.layers.Bidirectional`__.\n",
        "\n",
        "This one works just as `TimeDistributed` we saw before: you wrap it around a recurrent layer (SimpleRNN now and LSTM/GRU later) and it actually creates two layers under the hood.\n",
        "\n",
        "Your first task is to use such a layer our POS-tagger."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Двунаправленный RNN\n",
        "Поскольку мы анализируем полную последовательность, для нас законно просматривать будущие данные.\n",
        "\n",
        "Простой способ добиться этого - работать в обоих направлениях одновременно, создавая двунаправленный RNN.\n",
        "\n",
        "В Keras вы можете добиться этого как вручную (используя два элемента и объединение), так и с помощью __keras.layers.Bidirectional__.\n",
        "\n",
        "Этот работает точно так же, как __TimeDistributed__, который мы видели ранее: вы оборачиваете его вокруг повторяющегося слоя (SimpleRNN сейчас и LSTM / GRU позже), и это фактически создает два слоя под капотом.\n",
        "\n",
        "Ваша первая задача - использовать такой слой в нашем POS-теггере."
      ],
      "metadata": {
        "id": "uawALMeffs-9"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "xWfCrbh-8aHy"
      },
      "source": [
        "#Define a model that utilizes bidirectional SimpleRNN\n",
        "model = keras.models.Sequential()\n",
        "\n",
        "model.add(L.InputLayer([None],dtype='int32'))\n",
        "model.add(L.Embedding(len(all_words),50))\n",
        "model.add(L.Bidirectional(L.SimpleRNN(64,return_sequences=True)))\n",
        "\n",
        "#add top layer that predicts tag probabilities\n",
        "stepwise_dense = L.Dense(len(all_tags),activation='softmax')\n",
        "stepwise_dense = L.TimeDistributed(stepwise_dense)\n",
        "model.add(stepwise_dense)\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "Ort64W348aHz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eaf41903-ba4d-49e4-db44-ea4314718fe8"
      },
      "source": [
        "model.compile('adam','categorical_crossentropy')\n",
        "\n",
        "model.fit_generator(generate_batches(train_data),len(train_data)/BATCH_SIZE,\n",
        "                    callbacks=[EvaluateAccuracy()], epochs=5,)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-15-e75a6e7fae6a>:3: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  model.fit_generator(generate_batches(train_data),len(train_data)/BATCH_SIZE,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1344/1343 [==============================] - ETA: 0s - loss: 0.1942\n",
            "Measuring validation accuracy...\n",
            "448/448 [==============================] - 15s 32ms/step\n",
            "\n",
            "Validation accuracy: 0.95621\n",
            "\n",
            "1343/1343 [==============================] - 202s 148ms/step - loss: 0.1942\n",
            "Epoch 2/5\n",
            "1344/1343 [==============================] - ETA: 0s - loss: 0.0420\n",
            "Measuring validation accuracy...\n",
            "448/448 [==============================] - 14s 32ms/step\n",
            "\n",
            "Validation accuracy: 0.96037\n",
            "\n",
            "1343/1343 [==============================] - 177s 132ms/step - loss: 0.0420\n",
            "Epoch 3/5\n",
            "1344/1343 [==============================] - ETA: 0s - loss: 0.0351\n",
            "Measuring validation accuracy...\n",
            "448/448 [==============================] - 14s 32ms/step\n",
            "\n",
            "Validation accuracy: 0.96232\n",
            "\n",
            "1343/1343 [==============================] - 181s 134ms/step - loss: 0.0351\n",
            "Epoch 4/5\n",
            "1344/1343 [==============================] - ETA: 0s - loss: 0.0295\n",
            "Measuring validation accuracy...\n",
            "448/448 [==============================] - 15s 33ms/step\n",
            "\n",
            "Validation accuracy: 0.96226\n",
            "\n",
            "1343/1343 [==============================] - 183s 136ms/step - loss: 0.0295\n",
            "Epoch 5/5\n",
            "1344/1343 [==============================] - ETA: 0s - loss: 0.0248\n",
            "Measuring validation accuracy...\n",
            "448/448 [==============================] - 15s 33ms/step\n",
            "\n",
            "Validation accuracy: 0.96153\n",
            "\n",
            "1343/1343 [==============================] - 180s 134ms/step - loss: 0.0248\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7e393a78e3b0>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "iWHSkF648aHz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75796dbf-a9ed-4895-92e1-d084625d25f3"
      },
      "source": [
        "acc = compute_test_accuracy(model)\n",
        "print(\"\\nFinal accuracy: %.5f\"%acc)\n",
        "\n",
        "assert acc>0.96, \"Bidirectional RNNs are better than this!\"\n",
        "print(\"Well done!\")"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "448/448 [==============================] - 15s 33ms/step\n",
            "\n",
            "Final accuracy: 0.96153\n",
            "Well done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2DyAflw066m9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create **at least one experiment** from the list bellow, you can choose the most interesting and promising options to improve the performance of Bidirectional LSTM:\n",
        "\n",
        "* __Go beyond SimpleRNN__: there's `keras.layers.LSTM` and `keras.layers.GRU`\n",
        "  * If you want to use a custom recurrent Cell, read [this](https://keras.io/layers/recurrent/#rnn)\n",
        "  * You can also use 1D Convolutions (`keras.layers.Conv1D`). They are often as good as recurrent layers but with less overfitting.\n",
        "* __Stack more layers__: if there is a common motif to this course it's about stacking layers\n",
        "  * You can just add recurrent and 1dconv layers on top of one another and keras will understand it\n",
        "  * Just remember that bigger networks may need more epochs to train\n",
        "* __Regularization__: you can apply dropouts as usual but also in an RNN-specific way\n",
        "  * `keras.layers.Dropout` works inbetween RNN layers\n",
        "  * Recurrent layers also have `recurrent_dropout` parameter\n",
        "* __Gradient clipping__: If your training isn't as stable as you'd like, set `clipnorm` in your optimizer.\n",
        "  * Which is to say, it's a good idea to watch over your loss curve at each minibatch. Try tensorboard callback or something similar."
      ],
      "metadata": {
        "id": "y2kLQyJz7FRw"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TF1T00yr8RvM"
      },
      "source": [
        "# Попробуем обучить LSTM модель\n",
        "model = keras.models.Sequential()\n",
        "\n",
        "model.add(L.InputLayer([None],dtype='int32'))\n",
        "model.add(L.Embedding(len(all_words),50))\n",
        "model.add(L.Bidirectional(L.LSTM(64,return_sequences=True)))\n",
        "\n",
        "#add top layer that predicts tag probabilities\n",
        "stepwise_dense = L.Dense(len(all_tags),activation='softmax')\n",
        "stepwise_dense = L.TimeDistributed(stepwise_dense)\n",
        "model.add(stepwise_dense)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile('adam','categorical_crossentropy')\n",
        "\n",
        "model.fit_generator(generate_batches(train_data),len(train_data)/BATCH_SIZE,\n",
        "                    callbacks=[EvaluateAccuracy()], epochs=5,)"
      ],
      "metadata": {
        "id": "V2T0SMV37eSP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "551bbf41-b247-4193-a2bc-9e0b9f61090c"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-18-e75a6e7fae6a>:3: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  model.fit_generator(generate_batches(train_data),len(train_data)/BATCH_SIZE,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1344/1343 [==============================] - ETA: 0s - loss: 0.2623\n",
            "Measuring validation accuracy...\n",
            "448/448 [==============================] - 4s 7ms/step\n",
            "\n",
            "Validation accuracy: 0.95400\n",
            "\n",
            "1343/1343 [==============================] - 51s 33ms/step - loss: 0.2623\n",
            "Epoch 2/5\n",
            "1343/1343 [============================>.] - ETA: 0s - loss: 0.0452\n",
            "Measuring validation accuracy...\n",
            "448/448 [==============================] - 3s 6ms/step\n",
            "\n",
            "Validation accuracy: 0.96071\n",
            "\n",
            "1343/1343 [==============================] - 23s 17ms/step - loss: 0.0452\n",
            "Epoch 3/5\n",
            "1341/1343 [============================>.] - ETA: 0s - loss: 0.0374\n",
            "Measuring validation accuracy...\n",
            "448/448 [==============================] - 3s 7ms/step\n",
            "\n",
            "Validation accuracy: 0.96315\n",
            "\n",
            "1343/1343 [==============================] - 22s 17ms/step - loss: 0.0374\n",
            "Epoch 4/5\n",
            "1342/1343 [============================>.] - ETA: 0s - loss: 0.0322\n",
            "Measuring validation accuracy...\n",
            "448/448 [==============================] - 3s 6ms/step\n",
            "\n",
            "Validation accuracy: 0.96409\n",
            "\n",
            "1343/1343 [==============================] - 20s 15ms/step - loss: 0.0322\n",
            "Epoch 5/5\n",
            "1340/1343 [============================>.] - ETA: 0s - loss: 0.0288\n",
            "Measuring validation accuracy...\n",
            "448/448 [==============================] - 4s 9ms/step\n",
            "\n",
            "Validation accuracy: 0.96497\n",
            "\n",
            "1343/1343 [==============================] - 23s 17ms/step - loss: 0.0288\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7e392076b430>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "acc = compute_test_accuracy(model)\n",
        "print(\"\\nFinal accuracy: %.5f\"%acc)\n",
        "\n",
        "assert acc>0.96, \"Bidirectional RNNs are better than this!\"\n",
        "print(\"Well done!\")"
      ],
      "metadata": {
        "id": "K_MTU8a2wyuV",
        "outputId": "6cc67d22-169a-4fee-8dd3-31ec33f2a4e0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "448/448 [==============================] - 3s 7ms/step\n",
            "\n",
            "Final accuracy: 0.96497\n",
            "Well done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Метрика на 0,4% лучше чем у RNN"
      ],
      "metadata": {
        "id": "WnXlBEX5yCZl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Попробуем обучить GRU модель\n",
        "model = keras.models.Sequential()\n",
        "\n",
        "model.add(L.InputLayer([None],dtype='int32'))\n",
        "model.add(L.Embedding(len(all_words),50))\n",
        "model.add(L.Bidirectional(L.GRU(64,return_sequences=True)))\n",
        "\n",
        "#add top layer that predicts tag probabilities\n",
        "stepwise_dense = L.Dense(len(all_tags),activation='softmax')\n",
        "stepwise_dense = L.TimeDistributed(stepwise_dense)\n",
        "model.add(stepwise_dense)"
      ],
      "metadata": {
        "id": "9CP26LPwxm0L"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile('adam','categorical_crossentropy')\n",
        "\n",
        "model.fit_generator(generate_batches(train_data),len(train_data)/BATCH_SIZE,\n",
        "                    callbacks=[EvaluateAccuracy()], epochs=5,)"
      ],
      "metadata": {
        "id": "qDFi_dESxvgz",
        "outputId": "1694943a-3f7c-420a-b94c-f5b3a3bdce11",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-21-e75a6e7fae6a>:3: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  model.fit_generator(generate_batches(train_data),len(train_data)/BATCH_SIZE,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1341/1343 [============================>.] - ETA: 0s - loss: 0.1949\n",
            "Measuring validation accuracy...\n",
            "448/448 [==============================] - 4s 6ms/step\n",
            "\n",
            "Validation accuracy: 0.95794\n",
            "\n",
            "1343/1343 [==============================] - 46s 31ms/step - loss: 0.1946\n",
            "Epoch 2/5\n",
            "1341/1343 [============================>.] - ETA: 0s - loss: 0.0411\n",
            "Measuring validation accuracy...\n",
            "448/448 [==============================] - 3s 6ms/step\n",
            "\n",
            "Validation accuracy: 0.96209\n",
            "\n",
            "1343/1343 [==============================] - 20s 15ms/step - loss: 0.0411\n",
            "Epoch 3/5\n",
            "1343/1343 [============================>.] - ETA: 0s - loss: 0.0347\n",
            "Measuring validation accuracy...\n",
            "448/448 [==============================] - 3s 6ms/step\n",
            "\n",
            "Validation accuracy: 0.96441\n",
            "\n",
            "1343/1343 [==============================] - 22s 16ms/step - loss: 0.0347\n",
            "Epoch 4/5\n",
            "1340/1343 [============================>.] - ETA: 0s - loss: 0.0307\n",
            "Measuring validation accuracy...\n",
            "448/448 [==============================] - 3s 6ms/step\n",
            "\n",
            "Validation accuracy: 0.96542\n",
            "\n",
            "1343/1343 [==============================] - 22s 17ms/step - loss: 0.0307\n",
            "Epoch 5/5\n",
            "1340/1343 [============================>.] - ETA: 0s - loss: 0.0275\n",
            "Measuring validation accuracy...\n",
            "448/448 [==============================] - 3s 6ms/step\n",
            "\n",
            "Validation accuracy: 0.96583\n",
            "\n",
            "1343/1343 [==============================] - 20s 15ms/step - loss: 0.0275\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7e38e8308850>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "acc = compute_test_accuracy(model)\n",
        "print(\"\\nFinal accuracy: %.5f\"%acc)\n",
        "\n",
        "assert acc>0.96, \"Bidirectional RNNs are better than this!\"\n",
        "print(\"Well done!\")"
      ],
      "metadata": {
        "id": "jmLQKAn3x0fr",
        "outputId": "a8bdd5b9-6733-4a5f-b6da-07f15709d276",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "448/448 [==============================] - 3s 6ms/step\n",
            "\n",
            "Final accuracy: 0.96583\n",
            "Well done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "GRU улучшил результат еще на 0,1% Неплохо"
      ],
      "metadata": {
        "id": "YKQkrMGgzQL6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Добавим два разнонаправленных слоя и между ними dropout\n",
        "model = keras.models.Sequential()\n",
        "\n",
        "model.add(L.InputLayer([None],dtype='int32'))\n",
        "model.add(L.Embedding(len(all_words),50))\n",
        "model.add(L.Bidirectional(L.SimpleRNN(64,return_sequences=True)))\n",
        "model.add(L.Dropout(0.2))\n",
        "model.add(L.Bidirectional(L.SimpleRNN(64,return_sequences=True)))\n",
        "\n",
        "\n",
        "#add top layer that predicts tag probabilities\n",
        "stepwise_dense = L.Dense(len(all_tags),activation='softmax')\n",
        "stepwise_dense = L.TimeDistributed(stepwise_dense)\n",
        "model.add(stepwise_dense)"
      ],
      "metadata": {
        "id": "HmW2lE67zaul"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile('adam','categorical_crossentropy')\n",
        "\n",
        "model.fit_generator(generate_batches(train_data),len(train_data)/BATCH_SIZE,\n",
        "                    callbacks=[EvaluateAccuracy()], epochs=5,)"
      ],
      "metadata": {
        "id": "CMUjD2km2-SX",
        "outputId": "70ef0d66-ebbe-4f9b-dc54-8f0b48a3a353",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-28-e75a6e7fae6a>:3: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  model.fit_generator(generate_batches(train_data),len(train_data)/BATCH_SIZE,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1344/1343 [==============================] - ETA: 0s - loss: 0.1480\n",
            "Measuring validation accuracy...\n",
            "448/448 [==============================] - 29s 64ms/step\n",
            "\n",
            "Validation accuracy: 0.95769\n",
            "\n",
            "1343/1343 [==============================] - 388s 286ms/step - loss: 0.1480\n",
            "Epoch 2/5\n",
            "1344/1343 [==============================] - ETA: 0s - loss: 0.0414\n",
            "Measuring validation accuracy...\n",
            "448/448 [==============================] - 27s 61ms/step\n",
            "\n",
            "Validation accuracy: 0.96191\n",
            "\n",
            "1343/1343 [==============================] - 348s 259ms/step - loss: 0.0414\n",
            "Epoch 3/5\n",
            "1344/1343 [==============================] - ETA: 0s - loss: 0.0337\n",
            "Measuring validation accuracy...\n",
            "448/448 [==============================] - 27s 60ms/step\n",
            "\n",
            "Validation accuracy: 0.96384\n",
            "\n",
            "1343/1343 [==============================] - 344s 256ms/step - loss: 0.0337\n",
            "Epoch 4/5\n",
            "1344/1343 [==============================] - ETA: 0s - loss: 0.0278\n",
            "Measuring validation accuracy...\n",
            "448/448 [==============================] - 27s 60ms/step\n",
            "\n",
            "Validation accuracy: 0.96381\n",
            "\n",
            "1343/1343 [==============================] - 336s 250ms/step - loss: 0.0278\n",
            "Epoch 5/5\n",
            "1344/1343 [==============================] - ETA: 0s - loss: 0.0228\n",
            "Measuring validation accuracy...\n",
            "448/448 [==============================] - 29s 64ms/step\n",
            "\n",
            "Validation accuracy: 0.96268\n",
            "\n",
            "1343/1343 [==============================] - 345s 257ms/step - loss: 0.0228\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7e3919a634c0>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "acc = compute_test_accuracy(model)\n",
        "print(\"\\nFinal accuracy: %.5f\"%acc)\n",
        "\n",
        "assert acc>0.96, \"Bidirectional RNNs are better than this!\"\n",
        "print(\"Well done!\")"
      ],
      "metadata": {
        "id": "OVFusYm43DEy",
        "outputId": "6bd2cf1f-816e-4364-8d3d-f6310766d429",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "448/448 [==============================] - 29s 64ms/step\n",
            "\n",
            "Final accuracy: 0.96268\n",
            "Well done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "На двух слоях RNN и дропауте метрика незначительно  упала"
      ],
      "metadata": {
        "id": "K9fQxwiz_b5f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "2jaxJhoR_a-3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Попробуем два слоя GRU и в первый добавим параметр дропаут\n",
        "model = keras.models.Sequential()\n",
        "\n",
        "model.add(L.InputLayer([None],dtype='int32'))\n",
        "model.add(L.Embedding(len(all_words),50))\n",
        "model.add(L.Bidirectional(L.GRU(32,return_sequences=True, recurrent_dropout=0.2)))\n",
        "model.add(L.Bidirectional(L.GRU(64,return_sequences=True,)))\n",
        "\n",
        "#add top layer that predicts tag probabilities\n",
        "stepwise_dense = L.Dense(len(all_tags),activation='softmax')\n",
        "stepwise_dense = L.TimeDistributed(stepwise_dense)\n",
        "model.add(stepwise_dense)"
      ],
      "metadata": {
        "id": "UJl7ymL8_p90",
        "outputId": "5f8e4a56-2967-494a-bba0-24776a062f70",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer gru_11 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer gru_11 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer gru_11 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile('adam','categorical_crossentropy')\n",
        "\n",
        "model.fit_generator(generate_batches(train_data),len(train_data)/BATCH_SIZE,\n",
        "                    callbacks=[EvaluateAccuracy()], epochs=5,)"
      ],
      "metadata": {
        "id": "KL4Rm9yKAz5U",
        "outputId": "5025ee4c-95e7-43e7-e868-9f736de670c3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-35-e75a6e7fae6a>:3: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  model.fit_generator(generate_batches(train_data),len(train_data)/BATCH_SIZE,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1344/1343 [==============================] - ETA: 0s - loss: 0.1819\n",
            "Measuring validation accuracy...\n",
            "448/448 [==============================] - 51s 110ms/step\n",
            "\n",
            "Validation accuracy: 0.95645\n",
            "\n",
            "1343/1343 [==============================] - 695s 509ms/step - loss: 0.1819\n",
            "Epoch 2/5\n",
            "1344/1343 [==============================] - ETA: 0s - loss: 0.0417\n",
            "Measuring validation accuracy...\n",
            "448/448 [==============================] - 50s 112ms/step\n",
            "\n",
            "Validation accuracy: 0.96311\n",
            "\n",
            "1343/1343 [==============================] - 700s 521ms/step - loss: 0.0417\n",
            "Epoch 3/5\n",
            "1344/1343 [==============================] - ETA: 0s - loss: 0.0352\n",
            "Measuring validation accuracy...\n",
            "448/448 [==============================] - 49s 109ms/step\n",
            "\n",
            "Validation accuracy: 0.96503\n",
            "\n",
            "1343/1343 [==============================] - 670s 498ms/step - loss: 0.0352\n",
            "Epoch 4/5\n",
            "1344/1343 [==============================] - ETA: 0s - loss: 0.0311\n",
            "Measuring validation accuracy...\n",
            "448/448 [==============================] - 50s 111ms/step\n",
            "\n",
            "Validation accuracy: 0.96497\n",
            "\n",
            "1343/1343 [==============================] - 697s 519ms/step - loss: 0.0311\n",
            "Epoch 5/5\n",
            "1344/1343 [==============================] - ETA: 0s - loss: 0.0277\n",
            "Measuring validation accuracy...\n",
            "448/448 [==============================] - 49s 109ms/step\n",
            "\n",
            "Validation accuracy: 0.96686\n",
            "\n",
            "1343/1343 [==============================] - 661s 492ms/step - loss: 0.0277\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7e39161b4f40>"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "acc = compute_test_accuracy(model)\n",
        "print(\"\\nFinal accuracy: %.5f\"%acc)\n",
        "\n",
        "assert acc>0.96, \"Bidirectional RNNs are better than this!\"\n",
        "print(\"Well done!\")"
      ],
      "metadata": {
        "id": "c8Uk74flGdLc",
        "outputId": "afb808e8-6e50-4487-c9de-d7c72949d9bf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "448/448 [==============================] - 50s 110ms/step\n",
            "\n",
            "Final accuracy: 0.96686\n",
            "Well done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Самый лучший Результат!!!"
      ],
      "metadata": {
        "id": "lKUHp63iOnbN"
      }
    }
  ]
}